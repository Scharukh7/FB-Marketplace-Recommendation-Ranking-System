{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models, datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "products_df = '/home/shah/Desktop/FB-Marketplace-Recommendation-Ranking-System/data/df_from_demo.csv'\n",
    "image_folder = '/home/shah/Desktop/FB-Marketplace-Recommendation-Ranking-System/data/cleaned_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTextDataloader(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, Image_dir, csv_file, transform: transforms = None, labels_level : int=0, max_desc_len = 50):\n",
    "        self.products = pd.read_csv(csv_file, lineterminator='\\n')\n",
    "        self.root_dir = Image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        self.max_desc_len = max_desc_len\n",
    "        self.products['category'] = self.products['category'].apply(lambda x: self.get_category(x, labels_level))\n",
    "        self.descriptions = self.products['product_description']\n",
    "        self.image_id = self.products['id']\n",
    "        self.labels = self.products['category'].to_list()\n",
    "        self.num_classes = len(set(self.labels))\n",
    "\n",
    "\n",
    "        self.encoder = {y: x for (x, y) in enumerate(set(self.labels))}\n",
    "        self.decoder = {x: y for (x, y) in enumerate(set(self.labels))}\n",
    "\n",
    "        if transform == None:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(128),\n",
    "                transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "                transforms.RandomHorizontalFlip(p=0.3),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.CenterCrop(128)\n",
    "                ])\n",
    "\n",
    "\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self.vocab = self.get_vocab()\n",
    "        self.descriptions = self.tokenize_descriptions(self.descriptions)\n",
    "\n",
    "        assert len(self.descriptions) == len(self.labels) == len(self.image_id)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(self):\n",
    "\n",
    "    def yield_tokens():\n",
    "        for description in self.descriptions:\n",
    "            tokens = self.tokenizer(description)\n",
    "            yield tokens\n",
    "    token_generator = yield_tokens()\n",
    "\n",
    "    vocab = build_vocab_from_iterator(token_generator, specials=['<UNK>'])\n",
    "    print('length of vocab:', len(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_descriptions(self, descriptions):\n",
    "    def tokenize_description(description):\n",
    "        words = self.tokenizer(description)\n",
    "        words = words[:50]\n",
    "        pad_length = self.max_desc_len - len(words)\n",
    "        words.extend(['<UNK>'] * pad_length)\n",
    "        tokenized_desc = self.vocab(words)\n",
    "        tokenized_desc = torch.tensor(tokenized_desc)\n",
    "        return tokenized_desc\n",
    "\n",
    "    descriptions = descriptions.apply(tokenize_description)\n",
    "    return descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __len__(self):\n",
    "    return len(self.products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, index):\n",
    "    label = self.labels[index]\n",
    "    label = self.encoder[label]\n",
    "    label = torch.as_tensor(label)\n",
    "    print(self.products.iloc[index, 0])\n",
    "    image = os.path.join(self.root_dir, (self.products.iloc[index, 0].astype(str)))\n",
    "    image = torch.tensor(image).float()\n",
    "        # print(image)\n",
    "    image = io.imread(f'{image}.jpg')\n",
    "    image = self.transform(image)\n",
    "    description = self.descriptions[index]\n",
    "    return image, description, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def get_category(x, level: int = 0):\n",
    "    return x.split('/')[level].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = ImageTextDataloader(Image_dir='/home/shah/Desktop/FB-Marketplace-Recommendation-Ranking-System/data/cleaned_images',\n",
    "    csv_file='/home/shah/Desktop/FB-Marketplace-Recommendation-Ranking-System/data/df_from_demo.csv')\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=12,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "    for i, (image, description, labels) in enumerate(dataloader):\n",
    "        print(image)\n",
    "        print(labels)\n",
    "        print(description.size())\n",
    "        print(image.size())\n",
    "        if i == 0:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
