{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import torch.backends.cudnn as cudnn\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/shah/Desktop/FB-Marketplace-Recommendation-Ranking-System/data/y_label.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductImageCategoryDataset():\n",
    "    def __init__(self, root_dir, num_classes, transform=None):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.data = pd.read_csv(\"/home/shah/Desktop/FB-Marketplace-Recommendation-Ranking-System/data/y_label.csv\")\n",
    "        self.num_classes = num_classes\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name, label = self.data[index]\n",
    "        image_path = {x: datasets.ImageFolder(os.path.join(self.root_dir, image_name, x),\n",
    "                                          self.transform[x])\n",
    "                  for x in ['train', 'val']}\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        #image = np.array(imageio.imread(image_path))\n",
    "        #label = image_name[index]\n",
    "        label = int(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'ProductImageCategoryDataset' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7c2f8f0da0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m image_datasets = {\n\u001b[1;32m     27\u001b[0m     \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'ProductImageCategoryDataset' and 'str'"
     ]
    }
   ],
   "source": [
    "#split the dataset to train, val, test\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "root_dir = 'data/data_images/'\n",
    "\n",
    "dataset = ProductImageCategoryDataset(root_dir, num_classes=13, transform=data_transforms)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': \n",
    "    datasets.ImageFolder(root_dir + 'train', data_transforms['train']),\n",
    "    'val': \n",
    "    datasets.ImageFolder(root_dir + 'val', data_transforms['val']),\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=4,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0), \n",
    "    'val':\n",
    "    torch.utils.data.DataLoader(image_datasets['val'],\n",
    "                                batch_size=4,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0),\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = {x: (image_datasets) for x in ['train', 'val']}\n",
    "features, label = examples\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#summary(model_ft, (3, 64, 64))\n",
    "num_fltrs = model.fc.in_features\n",
    "num_classes = 13\n",
    "feature_extract = True\n",
    "\n",
    "model.fc = torch.nn.Linear(num_fltrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    #Train the model\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader['train'], 0):\n",
    "            #features, label = batch\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "\n",
    "                if (i+1) % 200 == 199:\n",
    "                    print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iteration}, loss: {running_loss / 200:.3f}, inputs {inputs.shape}')\n",
    "                    running_loss = 0.0\n",
    "        epoch_loss = running_loss / dataset_sizes\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "model_ft = train_model(model, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader['test']:\n",
    "                features, label = batch\n",
    "                test_output = model(features)\n",
    "                last_layer = test_output\n",
    "                pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "                correct += (pred_y == label).sum().item()\n",
    "                total += pred_y.size(0)\n",
    "        print('Got %d / %d correct (%.2f)' % (correct, total, float(correct / total)))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b099c207f7071e7802aeb8fc32298ef1a4dd7cfb6d3bb3ada8c8b299b44af55f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 ('rtx_3060')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
