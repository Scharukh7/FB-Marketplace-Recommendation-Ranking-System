{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shah/miniconda3/envs/selenium_project/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchdata as td\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductImageCategoryDataset():\n",
    "    def __init__(self, learning_rate = 1e-3):\n",
    "        super().__init__()\n",
    "        self.X = pd.read_pickle('data/image_model_X.pkl')\n",
    "        #self.X['image_array'] = self.X.values.tolist()\n",
    "        #self.X = self.X['image_array']\n",
    "        self.y = pd.read_pickle('data/image_model_y.pkl')\n",
    "        #print(train_X.shape)\n",
    "        #print(len(self.X))\n",
    "        #print(len(self.y))\n",
    "        assert len(self.X) == len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.X.iloc[index]\n",
    "        label = self.y.iloc[index]\n",
    "        #print(index)\n",
    "        features = torch.tensor(features).float()\n",
    "        #3=num of batch(get 3 images at every iteration of training the network)\n",
    "        features = features.reshape(3, 64, 64)\n",
    "        #print(features.shape)\n",
    "        label = int(label)\n",
    "        \n",
    "        return (features, label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "dataset = ProductImageCategoryDataset()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#split the dataset to train, val, test\n",
    "\n",
    "total_count = len(dataset)\n",
    "train_count = int(0.7 * total_count)\n",
    "valid_count = int(0.2 * total_count)\n",
    "test_count = total_count - train_count - valid_count\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, (train_count, valid_count, test_count)\n",
    ")\n",
    "\n",
    "#train_dataset = train_dataset.map(transform)\n",
    "\n",
    "train_loader = {\n",
    "    'train' : torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=1),\n",
    "    'validation': torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=True, num_workers=1),\n",
    "    'test' : torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=1)\n",
    "}\n",
    "dataset_sizes = {x: len(train_loader[x]) for x in ['train','validation','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 542, 'validation': 155, 'test': 78}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    #Train the model\n",
    "    since = time.time()\n",
    "    total_step = len(train_loader)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train','validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i, batch in enumerate(train_loader[phase]):\n",
    "        \n",
    "                features, label = batch\n",
    "                features = features.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(features)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, label)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                #if (i+1) % 100 == 0:\n",
    "                    #print('Epoch [{}/{}, Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "            \n",
    "                running_loss += loss.item() * features.size(0)\n",
    "                running_corrects += torch.sum(preds == label.data)\n",
    "        \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / total_step[phase]\n",
    "            epoch_acc = running_corrects.double() / total_step[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()            \n",
    "         \n",
    "\n",
    "#print('{} loss: {: {:.4f}, acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    time_elapsed = time.time() - since   \n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best Validation Acc: {best_acc:4f}')\n",
    "\n",
    "    #load best model weight\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#summary(model_ft, (3, 64, 64))\n",
    "num_fltrs = model.fc.in_features\n",
    "\n",
    "model.fc = torch.nn.Linear(num_fltrs, 13)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c14a6692a215417f5263d283ebf372218c2d1b9771ac18dab80d5263bb04c7bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('selenium_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
